最简单的回归线性模型是输入变量的线性组合：     

$$
y(x,w) = w_0 + w_1x_1+ ... + w_Dx_D \tag{3.1}
$$

其中$$ x = (x_1,...,x_D)^T$$。这通常简单的简单的叫做线性回归（linear regression）。这个模型的关键性属性是它是参数$$ w_0,...,w_D $$的一个线性函数。但是，它也是输入变量xi的一个线性函数，这给模型带来的极大的局限性。因此，我们将输入变量的确定的非线性函数进行线性组合来扩展模型的类别：    

$$
y(x,w) = w_0 + \sum\limits_{j=1}^{M-1}w_j\phi_j(x) \tag{3.2}
$$

其中$$ \phi_j(x) $$被称为基函数（basis function）。通过把下标$$ j $$的最大值记作$$ M − 1$$，使得这个模型中的参数总数为$$ M $$。    

参数$$ w_0 $$使得数据中可以存在任意的固定偏移，通常被称为偏置参数（bias parameter）（不要和统计观念下的“偏置”搞混淆）。通常，定义一个额外的占位“基函数”$$ \phi_0(x) = 1 $$是很方便的，以便：

$$
y(x,w) = \sum\limits_{j=0}^{M-1}w_j\phi_j(x) = w^T\phi(x) \tag{3.3}
$$

其中$$ w = (w_0,...,w_{M-1})^T , \phi = (\phi_0,...,\phi_{M-1})^T $$。
